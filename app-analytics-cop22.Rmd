---
title: "COP22 Datapack App Analytics"
output:
  pdf_document: default
html_document:
  df_print: paged
lang: "en-US"
date: '`r format(Sys.time(), "%d %B, %Y %H:%M")`'
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(data.table)
require(magrittr)
require(purrr)
require(dplyr)
require(tidyr)
require(knitr)
require(ggplot2)
require(paws)
require(connectapi)
require(lubridate)
require(noctua)
require(kableExtra)

#Set the AWS_ATHENA_S3_STAGING_DIR
ssm<-paws::ssm()
athena_staging_dir <- paste0("s3://",ssm$get_parameter(Name = "BucketProcessed")$Parameter$Value,"/datapack/temp/")
Sys.setenv(AWS_ATHENA_S3_STAGING_DIR = athena_staging_dir )

#Connect to the Athena database
con <- dbConnect(noctua::athena())


Sys.setlocale("LC_MESSAGES", 'en_GB.UTF-8')
Sys.setenv(LANG = "en_US.UTF-8")

```


## Summary info
```{r summary_info, eval=TRUE, echo=FALSE, message=FALSE}

d_events <- dbGetQuery(con,"SELECT event_type,tool,datapack_name,cop_year,
CAST(date_parse(ts, '%Y-%m-%dT%T+0000') as date) as event_date ,uuid,user
FROM datapack.cop22_app_events;")

events_type_map <- tibble::tribble(
  ~event_type, ~message,
  "VALIDATE","Validation",
  "COMPARISON_DOWNLOAD","Comparison",
  "MESSAGE_DOWNLOAD","Messages",
  "FLATPACK_DOWNLOAD", "Flatpack",
  "VR_RULES_DOWNLOAD","Validation rules",
  "DATAPACK_DOWNLOAD","Datapack",
  "CSO_FLATPACK_DOWNLOAD","CSO Flatpack",
  "MEMO_DOWNLOAD","COP Memo",
  "LOGIN","Login",
  "LOGIN_FAILED","Login failed",
  "MISSING_PSNUXIM_DOWNLOAD", "Missing PSNUxIM targets",
  "PAW_EXPORT", "PAW Export",
  "APPEND_PSNUXIM_DOWNLOAD", "Append missing targets",
  "UPDATED_TARGETS_DOWNLOAD", "Update PSNUxIM Targets"
)



# url <- paste0(d2_session$base_url,"api/users?paging=false&fields=userCredentials[username],userGroups[name]&filter=userCredentials.disabled:eq:false")
# r <-httr::GET(url,content_type_json(),handle=d2_session$handle) %>% 
#   httr::content(.,"text") %>% 
#   jsonlite::fromJSON()
# 
# uzers <- unlist(lapply(r$users$userCredentials$username, function(x) digest(x,"md5",serialize=FALSE)))
# has_validated <- uzers %in% d_events$user
# 
# uzers <- uzers[has_validated]
# ugs<- r$users$userGroups[has_validated]
# rm(r)
# 
# is_systems <-  unlist(lapply(ugs, function(x) any(stringr::str_detect(x$name,"Data PRIME Systems access"))))
# is_global <-  unlist(lapply(ugs, function(x) any(stringr::str_detect(x$name,"Global users"))))
# is_ou_agency <- unlist(lapply(ugs, function(x) any(stringr::str_detect(x$name,"^OU .+ Agency"))))
# is_interagency <- unlist(lapply(ugs, function(x) any(stringr::str_detect(x$name,"^OU .+ Interagency"))))
# is_partner <- unlist(lapply(ugs, function(x) any(stringr::str_detect(x$name,"^OU .+ Partner"))))
# 
# user_type <- data.frame(user=uzers,is_systems = is_systems,is_global=is_global,is_ou_agency=is_ou_agency,is_interagency = is_interagency,is_partner=is_partner)
# 
# user_type %<>% dplyr::mutate(user_type = dplyr::case_when(is_systems ~ "Systems",
#                                                          is_global & ! is_systems  ~ "Global",
#                                                          is_ou_agency ~ "Agency (OU)",
#                                                          is_interagency ~ "Interagency",
#                                                          TRUE ~ "Unknown")) %>% 
# dplyr::select(user,user_type)
# 
# d_events <- d_events %>% dplyr::inner_join(user_type)

start_date<-min(d_events$event_date)
end_date<-max(d_events$event_date)
d_events <- d_events %>%  dplyr::left_join(events_type_map)

validations <- d_events %>%  dplyr::filter(event_type == "VALIDATE") 

downloads <- d_events %>% dplyr::filter(stringr::str_detect(event_type,"DOWNLOAD"))

logins <- d_events %>% dplyr::filter(stringr::str_detect(event_type,"LOGIN")) %>% 
  dplyr::select(event_type, uuid, event_date) %>% 
  dplyr::left_join( {
    validations %>% 
      dplyr::select(tool, datapack_name, cop_year, uuid)
  }, by = c("uuid")) %>% 
  dplyr::mutate( tool = ifelse(is.na(tool),  "Unknown", tool),
                 datapack_name = ifelse(is.na(datapack_name), "Uknown", datapack_name),
                 cop_year = ifelse(is.na(cop_year), "Unknown", cop_year)) %>% 
  dplyr::arrange(cop_year, event_date)

```



- Total validations: `r NROW(validations)`
- Total downloads: `r NROW(downloads)`
- Unique users: `r length(unique(d_events$user))`
- Logins: `r NROW(logins)`
- Failed logins: `r dplyr::filter(d_events, event_type == "LOGIN_FAILED") %>% nrow()`
- Report period: `r start_date` to  `r end_date`

## Validations by country

```{r validations_by_country, eval=TRUE, echo=FALSE, message=FALSE}
validations_by_country_total<-
validations %>% 
  dplyr::select(Country=datapack_name, cop_year) %>%
  dplyr::filter(cop_year %in% datapackr::supportedCOPYears()) %>% 
  dplyr::group_by(Country, cop_year ) %>% 
  dplyr::summarise(Validations=dplyr::n(), .groups = "drop") %>% 
  dplyr::arrange(cop_year, Country) %>% 
  tidyr::pivot_wider(names_from=cop_year,values_from = Validations,values_fill = 0 )

#https://stackoverflow.com/questions/36067598/r-print-table-with-columns-sums-below
func <- function(z) if (is.numeric(z)) sum(z) else '' 
sumrow <- as.data.frame(lapply(validations_by_country_total, func))
sumrow[1] <- "Total"
names(sumrow) <- names(validations_by_country_total)
validations_by_country_total <- rbind(validations_by_country_total, sumrow)


knitr::kable(validations_by_country_total, booktabs = TRUE) %>% 
    kable_styling(bootstrap_options = c("striped", "condensed")) %>%
  row_spec(dim(validations_by_country_total)[1], bold = T) 
```

## Validations by day

```{r validations_by_date, eval=TRUE, echo=FALSE, message=FALSE}

#Validations by date
validations_by_date_total<-
validations %>% 
  dplyr::filter(cop_year %in% datapackr::supportedCOPYears()) %>% 
  dplyr::select(Date=event_date, cop_year) %>% 
  dplyr::group_by(Date, cop_year) %>% 
  dplyr::summarise(Validations = dplyr::n())

ggplot(validations_by_date_total,aes(x = Date, y= Validations)) + geom_col() + facet_grid(cop_year ~ .) 


```


## Downloads by day and type

```{r downloads_by_date, eval=TRUE, echo=FALSE, message=FALSE}

#Validations by date
downloads_by_day_type<-
downloads %>% 
  dplyr::filter(cop_year %in% datapackr::supportedCOPYears()) %>% 
  dplyr::select(Date=event_date,Type = message, Year = cop_year) %>%
  dplyr::mutate(Week = lubridate::isoweek(Date)) %>% 
  dplyr::group_by(Type,Week, Year) %>% 
  dplyr::summarise(Downloads = dplyr::n())

ggplot(downloads_by_day_type,aes(x = Week, y= Downloads, fill=Type)) + geom_bar(position="stack", stat="identity") + facet_grid(Year ~ .) 


```

### New users

```{r new_users, eval=TRUE, echo=FALSE, message=FALSE}
new_users <- d_events %>%
    dplyr::filter(cop_year %in% datapackr::supportedCOPYears()) %>% 
  dplyr::select(user,event_date) %>% 
  dplyr::group_by(user) %>%
  dplyr::arrange(event_date) %>%
  dplyr::filter(dplyr::row_number()==1) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(val=1) %>% 
  dplyr::select(event_date,val) %>% 
  dplyr::arrange(event_date) %>% 
  dplyr::mutate(val=cumsum(val))
  
  ggplot(new_users, aes(event_date,val)) + geom_step() + xlab("Date") + ylab("New users")

         
```

## Validation issues summary

The following table displays the summary of issues of the latest Target Setting Tool which was validated for a specific country or operating unit. Results are then 
aggregated across all operating units and the resulting percentage of issues which are common to all of the most recent submissions is shown. 

```{r issue_summary, eval=TRUE, echo=FALSE, }

#We need to swtich regions
Sys.setenv(AWS_REGION = "us-east-2")
s3<-paws::s3()
s3_files <- s3$list_objects_v2(Bucket=Sys.getenv("AWS_S3_BUCKET"),Prefix="validation_error_summary/cop23/") 
files_on_s3<-s3_files$Contents %>% map(.,function(x) x$Key) %>% unlist()
is_truncated <- s3_files$IsTruncated
coninutation_token <- s3_files$NextContinuationToken

#Get all of the files
while(is_truncated) {
  s3_files_next <- s3$list_objects_v2(Bucket=Sys.getenv("AWS_S3_BUCKET"),
                                      Prefix="validation_error_summary/cop23/",
                                      ContinuationToken = coninutation_token,
                                      StartAfter = files_on_s3[length(files_on_s3)])
  is_truncated <- s3_files_next$IsTruncated
  coninutation_token <- s3_files_next$NextContinuationToken
  
  files_next<-s3_files_next$Contents %>% map(.,function(x) x$Key) %>% unlist()
  
  files_on_s3 <- append(files_on_s3,files_next)
  is_truncated <- s3_files_next$IsTruncated
}


files_df <- stringr::str_split(files_on_s3,"_") %>% do.call("rbind.data.frame",.)
countries <- files_df[,3] %>% stringr::str_remove("summary/cop23/")
dates <- files_df[,4]
times  <- files_df[,5] %>%  stringr::str_remove(".csv")

dates_times <- paste(dates,times) %>% lubridate::as_datetime()

files_df <- data.frame(filename = files_on_s3,country=countries,ts = dates_times)

files_to_get <- files_df %>% group_by(country) %>% 
  dplyr::arrange(desc(ts),.by_group = TRUE) %>% 
  dplyr::mutate( is_first = dplyr::row_number() == 1) %>% 
  dplyr::ungroup() %>% 
  dplyr::filter(is_first) %>% 
  dplyr::pull(filename)

tmpdir<-tempdir()
dir.create(paste0(tmpdir,"/","validation_error_summary"),)
dir.create(paste0(tmpdir,"/","validation_error_summary/cop23"))

for ( i in 1:length(files_to_get) ) {

  s3_download<-s3$get_object( Bucket=Sys.getenv("AWS_S3_BUCKET"),
                 Key = files_to_get[i])
  s3_download_body <- s3_download$Body
  # Write output to file
file_name2 <- paste0(tmpdir,"/",files_to_get[i])
writeBin(s3_download_body, con = file_name2)
}

read_plus <- function(flnm) {
  data.table::fread(flnm) %>% 
    mutate(filename = flnm)
}

file_prefix<-paste0(tmpdir,"/validation_error_summary/cop23/")

d <- list.files(path = file_prefix,pattern = "*.csv",full.names = TRUE) %>% 
  map_df(~read_plus(.)) %>% 
  dplyr::mutate(`filename` = stringr::str_replace(filename,file_prefix,"")) %>% 
  tidyr::separate(`filename`,into=c("sanename","date","time"),sep="_") %>% 
  mutate(time=stringr::str_remove(time,"\\.csv$")) %>% 
  mutate(timestamp = lubridate::parse_date_time(paste(date,time),"ymd HMS")) %>% 
  dplyr::select(-date,-time)


issue_summary<-d %>%
  dplyr::select(country_name,validation_issue_category,count) %>%
  dplyr::group_by(validation_issue_category) %>%
  dplyr::summarise(count=dplyr::n()) %>%
  dplyr::arrange(-count) %>%
  dplyr::mutate(occurrence_rate = ( (100*count/length(files_to_get)) %>% round(.,digits = 1)  ) ) %>%
  dplyr::select(-count) %>%
  dplyr::rename(Category = validation_issue_category,
                "Occurrence (%)" = occurrence_rate)



kable(issue_summary,caption=paste("Validation summary ( n =",length(unique(d$uuid)),")"))

```

<!-- ```{r shiny_load_data, eval=FALSE, echo=FALSE} -->


<!-- days_back <- as.numeric(Sys.getenv("DAYSBACK", 365)) -->

<!-- default_content_title <- "Unknown (Deleted Content?)" -->

<!-- report_from <- lubridate::today() - lubridate::ddays(days_back) -->

<!-- client <- connectapi::connect() -->
<!-- shiny <- get_usage_shiny( -->
<!--   client, -->
<!--   from = report_from, -->
<!--   limit = Inf -->
<!-- ) %>% -->
<!--   mutate( -->
<!--     started = lubridate::ymd_hms(started), -->
<!--     ended = lubridate::ymd_hms(ended), -->
<!--     session_duration = ended - started -->
<!--     ) %>% -->
<!--   filter(session_duration > lubridate::dseconds(5)) -->

<!-- content <- get_usage_static( -->
<!--   client, -->
<!--   from = report_from, -->
<!--   limit = Inf -->
<!-- ) -->

<!-- all_users <- get_users(client, page_size = 500) -->

<!-- data <-   list(shiny = shiny, content = content) -->
<!-- ``` -->


<!-- ## Connect server stats -->
<!-- ```{r shiny_over_time, eval=TRUE, echo=FALSE} -->
<!-- data$shiny %>% -->
<!--     mutate(day = round_date(started, "day")) %>%  -->
<!--     group_by(day) %>%  -->
<!--     filter(day > today() - ddays(days_back)) %>%  -->
<!--     summarise(visits = n()) %>%  -->
<!--     arrange(desc(visits)) %>%  -->
<!--     {ggplot(., aes(day, visits)) +  -->
<!--             geom_bar(stat = "identity") +  -->
<!--             labs( -->
<!--                 y = "# of Shiny Sessions", -->
<!--                 x = NULL -->
<!--             )} -->
<!-- ``` -->


<!-- ## Datapack sessions by day -->
<!-- ```{r datapack_over_time, eval=FALSE, echo=FALSE} -->
<!-- data$shiny %>%  -->
<!--       mutate(time = ymd_hms(started), -->
<!--           day = round_date(started, "day")) %>%  -->
<!--   dplyr::select(content_guid,time,day) %>%  -->
<!--   group_by(content_guid,day) %>%  -->
<!--   summarize(visits = n()) %>%  -->
<!--   arrange(content_guid,desc(visits)) %>%  -->
<!--   mutate(name = purrr::map_chr(content_guid, ~ content_title(client, .x, default_content_title))) %>%  -->
<!--   dplyr::filter(name == Sys.getenv("APP_NAME")) %>%  -->
<!--   {  ggplot(., aes(day, visits)) +  -->
<!--      geom_bar(stat = "identity") +   -->
<!--      labs( -->
<!--        y = "# of Datapack sessions by day", -->
<!--        x = "Date" -->
<!--      )}  -->
<!-- ``` -->